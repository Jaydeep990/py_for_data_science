{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8eac8d",
   "metadata": {},
   "source": [
    "# Scraping The 300 Most Valuable Startups in India on Failory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442daf1",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/7kxTmF6/austin-distel-rxp-Th-Owu-Vg-E-unsplash.jpg\" alt=\"austin-distel-rxp-Th-Owu-Vg-E-unsplash\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e902b7",
   "metadata": {},
   "source": [
    "<big> **Web scraping** is the process of extracting and parsing data from websites in an automated fashion using a computer program. It's a useful technique for creating datasets for research and learning.<big>\n",
    "\n",
    "<big> **[Failory](https://www.failory.com/)**: A content site for startups founders. They publish weekly interviews and short and long-form articles to help you become a better founder.<big>\n",
    "\n",
    "<big> **Project Goal**: \n",
    "    \n",
    "The final output would be a list of the 300 most valuable startups along with their relevant details.\n",
    "    \n",
    "details such as:\n",
    "```\n",
    "Company Name            : Name of the Startup.\n",
    "Description             : What the company does.\n",
    "City                    : The City in which the startup is started.\n",
    "Year                    : The Year in which the startup was started.\n",
    "Founders                : Name of the founders of the startup.\n",
    "Industries              : Industrial domain in which the startup falls.\n",
    "No. of Employees        : Number of employees in the startup.\n",
    "Funding Amount          : Total funding amount funded to the startup.(in USD)\n",
    "Funding Round           : Number of Funding Round\n",
    "No. of Investors        : Number of investors in the startup.\n",
    "```\n",
    "<big>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6dba5d",
   "metadata": {},
   "source": [
    "## 1. Download & Parse webpage using Requests and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69c4ea",
   "metadata": {},
   "source": [
    "## 1.1 Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9206f3e7",
   "metadata": {},
   "source": [
    "All the lines of code together import the necessary libraries and modules to implement a web scraping project in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c21a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                       # for regular expressions\n",
    "import requests                 # to download web pages\n",
    "import numpy as np              # for numerical computing\n",
    "import pandas as pd             # for data manipulation\n",
    "from bs4 import BeautifulSoup   # parsing HTML content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca39322",
   "metadata": {},
   "source": [
    "### 1.2 Parsed HTML content of a web page using Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7182cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_startups_india_page():\n",
    "    \n",
    "    \"\"\"Returns the BeautifulSoup object for the web page at the URL 'https://www.failory.com/startups/india'.\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If the HTTP response status code is not 200 (OK).\n",
    "    \n",
    "    Returns:\n",
    "        BeautifulSoup: A BeautifulSoup object representing the parsed HTML content of the web page.\n",
    "    \"\"\"\n",
    "    \n",
    "    startups_india_url = 'https://www.failory.com/startups/india'\n",
    "    \n",
    "    response = requests.get(startups_india_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(startups_india_url))\n",
    "        \n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef495db",
   "metadata": {},
   "source": [
    "soup (BeautifulSoup): A BeautifulSoup object representing the parsed HTML content of a web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c29f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_startups_india_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b616345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT NAME : The 300 Most Valuable Startups in India\n"
     ]
    }
   ],
   "source": [
    "project_name = soup.title.text\n",
    "print(f\"PROJECT NAME : {project_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75e4f7",
   "metadata": {},
   "source": [
    "## 2. Extract the information into python list using Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637adee",
   "metadata": {},
   "source": [
    "### Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "183f8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves and returns a list of company names from a BeautifulSoup object.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A BeautifulSoup object representing the parsed HTML content of a web page.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of company names extracted from the given BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    company = []\n",
    "    \n",
    "    for companies in soup.find_all('h3', limit=300):\n",
    "        company_name = re.sub('[0-9]|\\)|amp;', '', companies.text).strip()\n",
    "        company.append(company_name)\n",
    "\n",
    "    return company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c3f40",
   "metadata": {},
   "source": [
    "### City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1805f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves and returns a list of city names from a BeautifulSoup object.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A BeautifulSoup object representing the parsed HTML content of a web page.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of city names extracted from the given BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    city = []\n",
    "\n",
    "    for details in soup.find_all('li'):\n",
    "        city_name = details.text.split('City: ')\n",
    "        if city_name[0] == '':\n",
    "            city.append(city_name[1])\n",
    "\n",
    "    return city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d13e3c",
   "metadata": {},
   "source": [
    "###  Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1cd80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves and returns a list of startup establishment years from a BeautifulSoup object.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A BeautifulSoup object representing the parsed HTML content of a web page.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of startup establishment years extracted from the given BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    year = []\n",
    "    \n",
    "    for details in soup.find_all('li'):\n",
    "        years = details.text.split('Started in: ')\n",
    "        if years[0] == '':\n",
    "            year.append(years[1])\n",
    "    \n",
    "    return year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b3484",
   "metadata": {},
   "source": [
    "### Founders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6be3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_founders(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a list of startup founders from a BeautifulSoup object.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A BeautifulSoup object representing the parsed HTML content of a web page.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of startup founders extracted from the given BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    founders = []\n",
    "    \n",
    "    containers = soup.find_all('ul', {'role': 'list'})[:300]\n",
    "    \n",
    "    for container in containers:\n",
    "        founder = container.find_all('li')[2].text.split('Founders: ')\n",
    "        if len(founder) == 2:\n",
    "            founders.append(founder[1])\n",
    "        else:\n",
    "            founders.append('N/A')\n",
    "    \n",
    "    return founders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ee7bd",
   "metadata": {},
   "source": [
    "### Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a16a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_industries(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a list of industries for the 300 most valuable startups in India.\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): A BeautifulSoup object representing the parsed HTML content of a web page.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of industries for the 300 most valuable startups in India.\n",
    "    \"\"\"\n",
    "    \n",
    "    industries = []\n",
    "    \n",
    "    containers = soup.find_all('ul',{'role':'list'})[:300]\n",
    "    \n",
    "    for container in containers:\n",
    "        details = container.find_all('li')\n",
    "        flag = False\n",
    "        \n",
    "        for detail in details:\n",
    "            if  'Industries: ' in detail.text:\n",
    "                flag = True\n",
    "                industry = detail.text.split( 'Industries: ')[1].strip()\n",
    "                \n",
    "        if flag:\n",
    "            industries.append(industry)\n",
    "        else:\n",
    "            industries.append('N/A')\n",
    "            \n",
    "    return industries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ec93f",
   "metadata": {},
   "source": [
    "### Number of employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c3816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_employees(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the number of employees for each startup from the Failory India page.\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): A BeautifulSoup object representing the parsed HTML content of a web page.\n",
    "\n",
    "    Returns:\n",
    "        A list of the number of employees for each startup.\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_employees = []\n",
    "    \n",
    "    containers = soup.find_all('ul',{'role':'list'})[:300]\n",
    "    \n",
    "    for container in containers:\n",
    "        details = container.find_all('li')\n",
    "        flag = False\n",
    "        \n",
    "        for detail in details:\n",
    "            if 'Number of employees: ' in detail.text:\n",
    "                flag = True\n",
    "                employees = detail.text.split('Number of employees:')[1].strip()\n",
    "                \n",
    "        if flag:\n",
    "            number_of_employees.append(employees)\n",
    "        else:\n",
    "            number_of_employees.append(0)\n",
    "    \n",
    "    return number_of_employees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6eeb2e",
   "metadata": {},
   "source": [
    "### Funding amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4048ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_funding_amount(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts funding amounts from a given Beautiful Soup object and returns a list of floats.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A Beautiful Soup object representing the HTML of a webpage.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of funding amounts in float format extracted from the Beautiful Soup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    funding_amount = []\n",
    "    \n",
    "    containers = soup.find_all('ul',{'role':'list'})[:300]\n",
    "    \n",
    "    for container in containers:\n",
    "        details = container.find_all('li')\n",
    "        flag = False\n",
    "        \n",
    "        for detail in details:\n",
    "            if 'Funding amount: ' in detail.text:\n",
    "                flag = True\n",
    "                amount = detail.text.split('Funding amount: ')[1].strip()\n",
    "                \n",
    "        if flag:\n",
    "            if 'â\\x82¹' in amount:\n",
    "                amount = str(int(amount[3:].replace(',','')) * 0.012)\n",
    "                funding_amount.append(amount)\n",
    "            else:\n",
    "                amount = re.sub('[,$]','',amount)\n",
    "                funding_amount.append(amount)\n",
    "        else:\n",
    "            funding_amount.append(0)\n",
    "    \n",
    "    return funding_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771bcd1f",
   "metadata": {},
   "source": [
    "### Number of funding rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0779c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_funding_rounds(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts the number of funding rounds from the given Beautiful Soup object.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A Beautiful Soup object representing the HTML of a webpage.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of integers representing the number of funding rounds extracted from the Beautiful Soup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    number_of_funding_rounds = []\n",
    "    \n",
    "    containers = soup.find_all('ul',{'role':'list'})[:300]\n",
    "    \n",
    "    for container in containers:\n",
    "        details = container.find_all('li')\n",
    "        flag = False\n",
    "        \n",
    "        for detail in details:\n",
    "            if 'Number of funding rounds: ' in detail.text:\n",
    "                flag = True\n",
    "                rounds = detail.text.split('Number of funding rounds: ')[1].strip()\n",
    "                \n",
    "        if flag:\n",
    "            number_of_funding_rounds.append(rounds)\n",
    "        else:\n",
    "            number_of_funding_rounds.append(0)\n",
    "    \n",
    "    return number_of_funding_rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf73e5a",
   "metadata": {},
   "source": [
    "### Number of investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f522f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_investors(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts the number of investors from the given Beautiful Soup object.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A Beautiful Soup object representing the HTML of a webpage.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of integers representing the number of investors extracted from the Beautiful Soup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    number_of_investors = []\n",
    "    \n",
    "    containers = soup.find_all('ul',{'role':'list'})[:300]\n",
    "    \n",
    "    for container in containers:\n",
    "        details = container.find_all('li')\n",
    "        flag = False\n",
    "        \n",
    "        for detail in details:\n",
    "            if 'Number of investors: ' in detail.text:\n",
    "                flag = True\n",
    "                investors = detail.text.split('Number of investors: ')[1].strip()\n",
    "                \n",
    "        if flag:\n",
    "            number_of_investors.append(investors)\n",
    "        else:\n",
    "            number_of_investors.append(0)\n",
    "    \n",
    "    return number_of_investors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51ecda",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d4c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts the descriptions from the given Beautiful Soup object.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A Beautiful Soup object representing the HTML of a webpage.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings representing the descriptions extracted from the Beautiful Soup object.\n",
    "    \"\"\"\n",
    "    \n",
    "    description = []\n",
    "    \n",
    "    for container in soup.find_all('figure'):\n",
    "        info = container.find_next_sibling('p').text\n",
    "        description.append(info)\n",
    "        \n",
    "    return description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5e088",
   "metadata": {},
   "source": [
    "## 3. Save the extracted information to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c97fb",
   "metadata": {},
   "source": [
    "DataFrame method to create pandas dataframe.\n",
    "\n",
    "The DataFrame has ten columns named 'Company', 'Description', 'City', 'Year', 'Founders', 'Industries', 'No. of Employees', 'Funding Amount', 'Funding Round', and 'No. of Investors'.\n",
    "\n",
    "Each of these columns contains data extracted from the corresponding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa86024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Company': get_company(soup),\n",
    "    'Description': get_description(soup),\n",
    "    'City': get_city(soup),\n",
    "    'Year': get_year(soup),\n",
    "    'Founders': get_founders(soup),\n",
    "    'Industries':get_industries(soup),\n",
    "    'No. of Employees': get_number_of_employees(soup),\n",
    "    'Funding Amount': get_funding_amount(soup),\n",
    "    'Funding Round' : get_number_of_funding_rounds(soup),\n",
    "    'No. of Investors': get_number_of_investors(soup)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c2650",
   "metadata": {},
   "source": [
    "This code converts selected columns of a DataFrame to specified data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffa5e6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company              object\n",
      "Description          object\n",
      "City                 object\n",
      "Year                  int32\n",
      "Founders             object\n",
      "Industries           object\n",
      "No. of Employees     object\n",
      "Funding Amount      float64\n",
      "Funding Round         int32\n",
      "No. of Investors      int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "convert_dtype = {\n",
    "    'Year': 'int32',\n",
    "    'Funding Amount': 'float64',\n",
    "    'Funding Round': 'int32',\n",
    "    'No. of Investors': 'int32'\n",
    "}\n",
    "\n",
    "df = df.astype(convert_dtype)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a5100",
   "metadata": {},
   "source": [
    "Use to_csv method to store required data in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3795a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('The 300 Most Valuable Startups in India.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571a30e",
   "metadata": {},
   "source": [
    "## 4. Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410f780",
   "metadata": {},
   "source": [
    "\n",
    "The project aims to scrape data from the Failory website to obtain details of the 300 most valuable startups in India. The data to be extracted includes:\n",
    "\n",
    "- Company name\n",
    "- Description\n",
    "- City\n",
    "- Year\n",
    "- Founders\n",
    "- Industries\n",
    "- Number of employees\n",
    "- Funding amount\n",
    "- Funding round\n",
    "- Number of investors\n",
    "\n",
    "The project uses Python and libraries such as Requests, BeautifulSoup, and Pandas for web scraping and data manipulation. Several functions are defined to extract each category of data, and the data is stored in Python lists. Finally, the data is combined into a Pandas DataFrame for easy manipulation and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027ffa0",
   "metadata": {},
   "source": [
    "## 5. References\n",
    "\n",
    "- Failory: https://www.failory.com/startups/india\n",
    "- Python: https://www.python.org/\n",
    "- Requests: https://docs.python-requests.org/en/latest/\n",
    "- BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- Pandas: https://pandas.pydata.org/\n",
    "- re : https://docs.python.org/3/library/re.html\n",
    "- Numpy: https://numpy.org/doc/stable/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
